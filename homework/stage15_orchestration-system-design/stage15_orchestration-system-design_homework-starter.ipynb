{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Starter — Stage 15: Orchestration & System Design\n",
    "Complete the sections below. Keep your answers concise and focused on orchestration readiness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Project Task Decomposition\n",
    "List 4–8 tasks. Add more rows as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Options Pricing Model Pipeline Tasks\n",
    "tasks = pd.DataFrame({\n",
    "    'task': ['data_fetch', 'data_validate', 'feature_engineer', 'model_train', 'model_evaluate', 'model_deploy', 'generate_report'],\n",
    "    'inputs': [\n",
    "        'API endpoints, config.py',\n",
    "        'data/raw/options_data_YYYYMMDD.csv',\n",
    "        'data/processed/validated_data.csv', \n",
    "        'data/processed/features_YYYYMMDD.csv',\n",
    "        'model + test data',\n",
    "        'trained model',\n",
    "        'all pipeline artifacts'\n",
    "    ],\n",
    "    'outputs': [\n",
    "        'data/raw/options_data_YYYYMMDD.csv',\n",
    "        'data/processed/validated_data.csv',\n",
    "        'data/processed/features_YYYYMMDD.csv',\n",
    "        'model/options_pricing_model.pkl',\n",
    "        'reports/evaluation_metrics.json',\n",
    "        'Flask API + Streamlit app',\n",
    "        'reports/stakeholder_report.md'\n",
    "    ],\n",
    "    'idempotent': [True, True, True, False, True, False, True]\n",
    "})\n",
    "\n",
    "print(\"Options Pricing Model Pipeline Tasks:\")\n",
    "tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Dependencies (DAG)\n",
    "\n",
    "### Options Pricing Model Pipeline Dependencies\n",
    "\n",
    "```\n",
    "data_fetch\n",
    "    ↓\n",
    "data_validate\n",
    "    ↓\n",
    "feature_engineer\n",
    "    ↓\n",
    "model_train ──→ model_evaluate\n",
    "    ↓              ↓\n",
    "model_deploy   generate_report\n",
    "```\n",
    "\n",
    "**Sequential Core**: Data flows through fetch → validate → engineer → train  \n",
    "**Parallel Branches**: After training, evaluation and deployment can run independently  \n",
    "**Report Generation**: Waits for all upstream tasks for comprehensive summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options Pricing Model DAG Dependencies\n",
    "dag = {\n",
    "    'data_fetch': [],\n",
    "    'data_validate': ['data_fetch'],\n",
    "    'feature_engineer': ['data_validate'],\n",
    "    'model_train': ['feature_engineer'],\n",
    "    'model_evaluate': ['model_train'],\n",
    "    'model_deploy': ['model_train'],\n",
    "    'generate_report': ['model_evaluate', 'model_deploy']\n",
    "}\n",
    "\n",
    "print(\"Pipeline Dependencies:\")\n",
    "for task, deps in dag.items():\n",
    "    deps_str = ', '.join(deps) if deps else 'None (root task)'\n",
    "    print(f\"{task}: depends on [{deps_str}]\")\n",
    "    \n",
    "dag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Logging & Checkpoints Plan\n",
    "Specify what you will log and where you will checkpoint for each task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options Pricing Model Logging & Checkpoint Plan\n",
    "logging_plan = pd.DataFrame({\n",
    "    'task': ['data_fetch', 'data_validate', 'feature_engineer', 'model_train', 'model_evaluate', 'model_deploy', 'generate_report'],\n",
    "    'log_location': [\n",
    "        'logs/data_fetch_YYYYMMDD.log',\n",
    "        'logs/data_validate_YYYYMMDD.log', \n",
    "        'logs/feature_eng_YYYYMMDD.log',\n",
    "        'logs/model_train_YYYYMMDD.log',\n",
    "        'logs/model_eval_YYYYMMDD.log',\n",
    "        'logs/deployment_YYYYMMDD.log',\n",
    "        'logs/reporting_YYYYMMDD.log'\n",
    "    ],\n",
    "    'log_messages': [\n",
    "        'start/end, rows fetched, API response codes',\n",
    "        'validation rules passed/failed, null rates',\n",
    "        'features created, distribution stats',\n",
    "        'hyperparameters, training metrics, convergence',\n",
    "        'performance metrics, bootstrap results',\n",
    "        'API health checks, service status',\n",
    "        'artifacts processed, report sections'\n",
    "    ],\n",
    "    'checkpoint_artifact': [\n",
    "        'data/raw/options_data_YYYYMMDD.csv',\n",
    "        'data/processed/validated_data.csv',\n",
    "        'data/processed/features_YYYYMMDD.csv',\n",
    "        'model/options_pricing_model.pkl',\n",
    "        'reports/evaluation_metrics.json',\n",
    "        'deployment status log',\n",
    "        'reports/stakeholder_report.md'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Logging & Checkpoint Strategy:\")\n",
    "logging_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Right-Sizing Automation\n",
    "Which parts will you automate now? Which stay manual? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automation Strategy for Options Pricing Model\n",
    "\n",
    "**Automate Now (High Value, Low Risk):**\n",
    "- **data_fetch**: Scheduled daily at market close (6 PM EST) - deterministic API calls\n",
    "- **data_validate**: Immediate validation with automated alerts - well-defined rules  \n",
    "- **feature_engineer**: Deterministic transformations (moneyness, vol-time) - safe to automate\n",
    "- **generate_report**: Template-based reporting with consistent output format\n",
    "\n",
    "**Keep Manual (High Risk, Requires Judgment):**\n",
    "- **model_train**: Requires hyperparameter tuning and performance validation\n",
    "- **model_evaluate**: Results need human interpretation for business context (R² only 15.6%)\n",
    "- **model_deploy**: Production deployment requires careful validation and rollback planning\n",
    "\n",
    "**Rationale**: Given the model's current limitations (low R², high uncertainty), human oversight is critical for model-related tasks. Data processing tasks are well-understood and provide immediate automation value through consistency and reliability.\n",
    "\n",
    "**Future Automation**: Consider automating model tasks when R² consistently exceeds 25% and comprehensive drift detection is implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) (Stretch) Refactor One Task into a Function + CLI\n",
    "Use the templates below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, json, logging, sys\n",
    "from datetime import datetime\n",
    "\n",
    "def my_task(input_path: str, output_path: str) -> None:\n",
    "    '''Example task template: read → transform → write JSON.'''\n",
    "    logging.info('[my_task] start')\n",
    "    # TODO: implement your logic\n",
    "    result = {'run_at': datetime.utcnow().isoformat(), 'note': 'replace with real output'}\n",
    "    Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    Path(output_path).write_text(json.dumps(result, indent=2))\n",
    "    logging.info('[my_task] wrote %s', output_path)\n",
    "\n",
    "def main(argv=None):\n",
    "    parser = argparse.ArgumentParser(description='Homework task wrapper')\n",
    "    parser.add_argument('--input', required=True)\n",
    "    parser.add_argument('--output', required=True)\n",
    "    args = parser.parse_args(argv)\n",
    "    logging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler(sys.stdout)])\n",
    "    my_task(args.input, args.output)\n",
    "\n",
    "if **name** == '**main**'':\n",
    "    # Example simulated CLI in notebook:\n",
    "    main(['--input', 'data/in.ext', '--output', 'data/out.json'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Simple Retry Wrapper (fill in)\n",
    "Add a small retry with linear backoff to harden a task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def retry(n_tries=3, delay=0.2):\n",
    "    def wrapper(fn, *args, **kwargs):\n",
    "        # TODO: implement try/except loop with sleep backoff\n",
    "        return fn(*args, **kwargs)\n",
    "    return wrapper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
